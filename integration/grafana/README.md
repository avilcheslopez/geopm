# Grafana

This directory contains a JSON file for the GEOPM `Grafana` dashboard that
visualizes metrics generated by the `geopmexporter(1)` Prometheus data source.
Additionally the directory contains a script to enable the monitoring of jobs
launched using the PBS HPC resource manager.


## Importing the Grafana dashboard

Follow the steps documented in the official Grafana user guide
<https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/import-dashboards/>
to import any of the JSON files in this directory for generating
the preferred visualizations. 


## Data Source for the Visuals

Grafana is capable of sourcing telemetry data from Prometheus
clients running on remote hosts. One such Prometheus exporter
is the `geopmexporter(1)` 
<https://geopm.github.io/geopmexporter.1.html> which leverages
`geopm.stats.collector` to summarize the metrics. The dashboard
file - `GEOPM_Report.grafana.dashboard.json`, in this directory, 
relies on `geopmexporter(1)` for its data source.


## Use case: Monitoring PBS jobs

The `geopmexporter(1)` is typically deployed system-wide with either a systemd
service or as a kubernetes service.  This documentation is for an alternative
`geopmexporter(1)` deployment scenario where an unprivileged user of a PBS
managed system would like to monitor the compute resources granted to the user
only while they are allocated.  This methodology should not be applied for
system-wide monitoring by an administrator, but rather for job monitoring by an
end user of a PBS system where the geopmexporter is not deployed system-wide.

A script is provided called `pbs_prometheus_launch.py` that can be used to:

- Assist with the initial one-time configuration of the Grafana server
- Monitor jobs submitted to a PBS batch system
- Review data collected from previously monitored jobs

The script runs the Prometheus and Grafana server on the head node of a
system. Optionally the script may also deploy and connect to `geopmexporter(1)`
clients running on the allocated nodes of a user's job.


### Requirements

A user installation of Grafana and Prometheus is required.  We recommend
following the installation instructions
[here](https://grafana.com/grafana/download?platform=linux) to `wget` the
Grafana archive for Linux.  The expanded archive is the `GRAFANA_DIR` provided
to the `pbs_prometheus_launch.py` script CLI.  To install Prometheus download
the archive for the latest stable Linux release from
[here](https://prometheus.io/download/).  The expanded archive is the
`PROMETHEUS_DIR` provided to the `pbs_prometheus_launch.py` script CLI.

Until the `geopmexporter(1)` is available in a stable release, the user must
build and install a development snapshot of GEOPM.

```bash
    # Install latest development snapshot of GEOPM
    GEOPM_BUILD=... # target installation directory
    wget https://raw.githubusercontent.com/geopm/geopm/refs/heads/dev/geopmdpy/install_user.sh
    chmod a+x install_user.sh
    ./install_user.sh --prefix=$GEOPM_BUILD --enable-levelzero
```


### Configuring ports

There are three ports used by the script to communicate:

- Prometheus server port opened on the head node (default 9090)
- Grafana server port opened on the head node (default 3000)
- Prometheus client port opened on the allocated nodes (default 8000)

To avoid conflicts, or firewall limitations, the user may override the defaults
using command line arguments to pbs_prometheus_launch.py

### Configuring Grafana Server

Before deploying the GEOPM Prometheus exporter across the system for the first
time, the Grafana server needs to be configured on the head node by setting the
administrator password and uploading the GEOPM Power Dashboard though the web
GUI.

To set the administrator password for your Grafana instance with the `grafana-cli`
tool run the following command inside of the Grafana software directory:

```bash
    cd $GRAFANA_DIR/
     ./bin/grafana-cli admin reset-admin-password $GRAFANA_ADMIN_PASSWORD
```

To add the GEOPM Prometheus dashboard to your Grafana configuration the Grafana
and Prometheus servers must be running.  This is done by executing the
`pbs_prometheus_launch.py` script without specifying the `--jobid` option.  This
will bring up the Prometheus server and Grafana server on the head node.

Then navigate to the Grafana web GUI in a web browser to import the GEOPM
Dashboard.  The Grafana server will be running an http (not https) server on the
head node URL on port 3000 (port can be modified with the the --graf-port option
to `pbs_prometheus_launch.py`).  For example if the head node hostname is
`login.cluster.acme.com` then the Grafana server is reached through the URL
`http://login.cluster.acme.com:3000`.  Login into the Grafana web page with the
`admin` user credentials set previously using the `grafana-cli` tool.  Once
logged in, add the http Prometheus data source using port 9090 (unless overridden
with the --prom-port option to `pbs_prometheus_launch.py`),
e.g.`http://localhost:9090`.  Next, import the [GEOPM Power Report Grafana
dashboard configuration
file](https://raw.githubusercontent.com/geopm/geopm/refs/heads/dev/integration/grafana/GEOPM_Report.grafana.dashboard.json)
using the Prometheus data source by drag-and-drop or copy-paste.


### Monitor the user job using the GEOPM Prometheus & Grafana framework
Now that you have configured Grafana and Prometheus, you can launch the Prometheus
client exporters across the allocated nodes of a job, and then use the Grafana Web GUI
(running on port `GRAFANA_SERVER_PORT` to monitor the aggregated telemetry.

First submit a job to the PBS queue using qsub to obtain a PBS Job ID.  Use the
PBS Job ID (`JOBID`) of the submitted job when launching the servers:

```bash
    JOBID=$(qsub ...)
    ./pbs_prometheus_launch.py --geopm-prefix GEOPM_DIR --jobid JOBID PROMETHEUS_DIR GRAFANA_DIR

```

The script will print the path to three logs that can be used to monitor the
Grafana server, Prometheus server, and Prometheus clients.  The servers running
on the login node will be terminated by the script when the allocation
completes.